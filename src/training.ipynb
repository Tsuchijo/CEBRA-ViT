{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cebra\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import itertools\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import gc\n",
    "from cebra_utils import *\n",
    "from vit_pytorch import ViT\n",
    "import pandas as pd\n",
    "\n",
    "data_path = '/mnt/teams/TM_Lab/Tony/water_reaching/Data/rig1_data/processed/GRL3_2023-07-13_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 187)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_data = load_pose_data(data_path, 0)\n",
    "## convert pose data to a numpy array size rows x columns\n",
    "pose_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given the path to a tif file, return that as a 3d numpy array\n",
    "# @param path: path to tif file\n",
    "# @return: 3d numpy array, first array is time dimension\n",
    "def load_tif(path):\n",
    "    img = cv2.imreadmulti(path, flags=(cv2.IMREAD_GRAYSCALE | cv2.IMREAD_ANYDEPTH))[1]\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "## Loads the brain data from a given trial\n",
    "def load_brain_data(parent_directory, trial_num, type='gcamp'):\n",
    "    # Load the data\n",
    "    data_path = os.path.join(parent_directory, 'trial_' + str(trial_num) + '/brain/' + type + '.tif')\n",
    "    data = load_tif(data_path)\n",
    "    return data\n",
    "\n",
    "def load_pose_data(parent_directory, trial_num):\n",
    "    # Load the data\n",
    "    data_path = os.path.join(parent_directory, 'trial_' + str(trial_num) + '/anipose/videos/pose-3d/vid.csv')\n",
    "    data = pd.read_csv(data_path)\n",
    "    data = data.to_numpy()\n",
    "    return data\n",
    "\n",
    "## Go through all trials and load the brain data for each trial\n",
    "def load_all_brain_data_trials(parent_directory, type='gcamp'):\n",
    "    # Get the number of trials\n",
    "    num_trials = len([x for x in os.listdir(parent_directory) if 'trial_' in x])\n",
    "    # Load the data\n",
    "    return np.array([load_brain_data(parent_directory, trial_num, type) for trial_num in range(num_trials)])\n",
    "    \n",
    "## Takes a numpy array in and returns a memory mapped numpy array\n",
    "# @param arr: numpy array to be memory mapped\n",
    "# @param path: path to save the memory mapped array to\n",
    "# @return: memory mapped numpy array\n",
    "def memmap(arr, path):\n",
    "    # Save the array\n",
    "    np.save(path, arr)\n",
    "    # Load the array\n",
    "    return np.load(path, mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([288, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "brain_images = load_brain_data(data_path, 1)\n",
    "brain_images = np.array([cv2.resize(x, (256, 256)) for x in brain_images])\n",
    "# convert each image to rgb (3 channels)\n",
    "brain_images = np.array([np.stack((x,)*3, axis=0) for x in brain_images])\n",
    "# to torch\n",
    "brain_images = torch.from_numpy(brain_images).float()\n",
    "print(brain_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates a CEBRA multisession Data Loader with the given data, feature data and brain data must share first 2 dimensions\n",
    "def init_dataloader(brain_data, feature_data, num_steps, time_offset, conditional, batch_size=1, cebra_offset=None ):\n",
    "    datasets = []\n",
    "    print('loading data')\n",
    "    for session in zip(brain_data, feature_data):\n",
    "        brain_data_tensor  = torch.FloatTensor(session[0]).unsqueeze(1)\n",
    "        feature_data_tensor = torch.FloatTensor(session[1])\n",
    "        datasets.append(cebra.data.datasets.TensorDataset(brain_data_tensor, continuous=feature_data_tensor, offset=cebra_offset))\n",
    "    dataset_collection = cebra.data.datasets.DatasetCollection(*datasets)\n",
    "    return cebra.data.multi_session.ContinuousMultiSessionDataLoader(\n",
    "        dataset=dataset_collection,\n",
    "        batch_size=batch_size,\n",
    "        num_steps=num_steps,\n",
    "        time_offset=time_offset,\n",
    "        conditional=conditional,\n",
    "    ).to('cuda')\n",
    "\n",
    "## initialize a single session dataloader\n",
    "def init_single_session_dataloader(brain_data, feature_data, num_steps, time_offset, conditional, batch_size=1, cebra_offset=None ):\n",
    "    brain_data_tensor  = torch.FloatTensor(brain_data).unsqueeze(1)\n",
    "    feature_data_tensor = torch.FloatTensor(feature_data)\n",
    "    dataset = cebra.data.datasets.TensorDataset(brain_data_tensor, continuous=feature_data_tensor, offset=cebra_offset)\n",
    "    return cebra.data.single_session.ContinuousDataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_steps=num_steps,\n",
    "        time_offset=time_offset,\n",
    "        conditional=conditional,\n",
    "    ).to('cuda')\n",
    "\n",
    "## Creat and train the model in partial batches of data\n",
    "def train_model(brain_data, feature_data, num_steps, time_offset, conditional, batch_size, cebra_offset, input_size, hidden_units, output_dimension, model_name, device, output_model_path, saved_model = None):\n",
    "    ## Load dataloader for first slice of data\n",
    "    print('Loading data')\n",
    "    dataloader= init_single_session_dataloader(brain_data, feature_data, num_steps, time_offset, conditional, batch_size, cebra_offset)\n",
    "    print('Creating model')\n",
    "    ## create list of models\n",
    "    model = torch.nn.ModuleList([\n",
    "    cebra.models.init(model_name, input_size,\n",
    "                        hidden_units, output_dimension, True)\n",
    "    for _ in range(len(list(dataloader.dataset.iter_sessions())))\n",
    "    ]).to(device)\n",
    "    if saved_model is not None:\n",
    "        model.__setstate__(saved_model)\n",
    "\n",
    "    ## Load criterion\n",
    "    criterion = cebra.models.criterions.LearnableCosineInfoNCE(temperature=1, min_temperature=0.1).to(device)\n",
    "    start_state = criterion.state_dict()\n",
    "    ## Load optimizer\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + list(criterion.parameters()), lr=0.001)\n",
    "\n",
    "    print('Loading solver')\n",
    "    ## Load solver and train on first slice of data\n",
    "    solver = cebra.solver.MultiSessionSolver(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        tqdm_on=True,\n",
    "    ).to(device)\n",
    "    print('Training on slice 1')\n",
    "    solver.fit(dataloader.to(device),\n",
    "                save_frequency=500,\n",
    "                logdir='runs',)\n",
    " \n",
    "    print('Training complete, saving model')\n",
    "    torch.save(solver, output_model_path)\n",
    "    return solver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data = np.array([load_brain_data(data_path, x) for x in range(1)])\n",
    "feature_data = np.array([load_pose_data(data_path, x) for x in range(1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape all images in brain data to be 256 x 256\n",
    "# 20 x 288 x 253 x 190 -> 20 x 288 x 256 x 256\n",
    "brain_data = np.array([np.array([cv2.resize(img, (256, 256)) for img in trial]) for trial in brain_data])\n",
    "brain_images = np.array([np.stack((x,)*3, axis=1) for x in brain_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 288, 3, 256, 256)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Creating model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TensorDataset' object has no attribute 'iter_sessions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# For ViT model we need to reshape the data to be 256 x 256 x 3 as the model expects 3 channels, so we use a 1,2 offset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     brain_data\u001b[39m=\u001b[39;49mbrain_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     feature_data\u001b[39m=\u001b[39;49mfeature_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     num_steps\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     time_offset\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     conditional\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtime_delta\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     cebra_offset\u001b[39m=\u001b[39;49mcebra\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mdatatypes\u001b[39m.\u001b[39;49mOffset(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     input_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     hidden_units\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     output_dimension\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mViT-16-v1\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     output_model_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodel.pth\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "\u001b[1;32m/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCreating model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m## create list of models\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModuleList([\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m cebra\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39minit(model_name, input_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                     hidden_units, output_dimension, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(dataloader\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49miter_sessions())))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m ])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m saved_model \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Water_Reaching_Classifier/src/training.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     model\u001b[39m.\u001b[39m__setstate__(saved_model)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorDataset' object has no attribute 'iter_sessions'"
     ]
    }
   ],
   "source": [
    "# For ViT model we need to reshape the data to be 256 x 256 x 3 as the model expects 3 channels, so we use a 1,2 offset\n",
    "model = train_model(\n",
    "    brain_data=brain_data,\n",
    "    feature_data=feature_data,\n",
    "    num_steps=100,\n",
    "    time_offset=10,\n",
    "    conditional='time_delta',\n",
    "    batch_size=2,\n",
    "    cebra_offset=cebra.data.datatypes.Offset(1,2),\n",
    "    input_size=256,\n",
    "    hidden_units=3,\n",
    "    output_dimension=16,\n",
    "    model_name='ViT-16-v1',\n",
    "    device='cuda',\n",
    "    output_model_path='model.pth',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
